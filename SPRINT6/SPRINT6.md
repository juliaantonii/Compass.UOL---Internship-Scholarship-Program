# üîñ **SUM√ÅRIO**

Nesta p√°gina encontra-se 4 T√≥picos Principais, s√£o estes:

+ **[Data Analytics Fundamentals](#1-data-analytics-fundamentals);**
+ **[Data Analytics on AWS - Business](#2-data-analytics-on-aws---business);**
+ **[Exerc√≠cios - Laborat√≥rios AWS](#exerc√≠cios---laborat√≥rios-aws);**
  + **[Lab AWS S3](#2-lab-aws-s3);**
  + **[Lab AWS Athena](#3-lab-aws-athena);**
  + **[Lab AWS Lambda](#4-lab-aws-lambda);**
+ **[Certifica√ß√£o](#üìù-certifica√ß√£o).**

---

&nbsp;

# 1. Data Analytics Fundamentals

##  Introdu√ß√£o

Neste t√≥pico vamos analisar o conceito de an√°lise de dados e as solu√ß√µes de avalia√ß√£o de dados, al√©m dos cinco desafios da avalia√ß√£o de dados, isto √©, os 5 V's.

+ **Avalia√ß√£o:** √â um exame detalhado de algo para entender sua natureza ou determinar suas caracter√≠sticas essenciais.

+ **Avalia√ß√£o de Dados:** √â o processo de compilar, processar e analisar dados para que voc√™ possa us√°-los para tomar decis√µes.

## Volume

Quando as empresas t√™m mais dados do que conseguem processar e analisar, elas t√™m um problema de volume.

<div align="center">

![Volume](<Images Sprint6/Volume.jpg>)

</div>

H√° tr√™s classifica√ß√µes amplas de tipos de origem dos dados:

+ **Dados Estruturados:** s√£o organizados e armazenados na forma de valores que s√£o agrupados em linhas e colunas de uma tabela.

+ **Dados Semiestruturados:** muitas vezes s√£o armazenados em conjuntos de pares de chave-valor que s√£o agrupados em elementos em um arquivo.

+ **Dados N√£o Estruturados:** n√£o s√£o estruturados de forma consistente. Alguns dados podem ter uma estrutura semelhante a dados semiestruturados, mas outros podem conter apenas metadados.

O Amazon S3 √© um armazenamento de objetos criado para armazenar e recuperar qualquer quantidade de dados de qualquer lugar. Para aproveitar ao m√°ximo o Amazon S3, voc√™ precisa entender alguns conceitos simples. Em primeiro lugar, o Amazon S3 armazena dados como objetos em buckets.

+ **Objeto:** √â composto por um arquivo e quaisquer metadados que descrevam esse arquivo.

+ **Buckets:** S√£o cont√™ineres l√≥gicos para objetos.

Depois que os objetos foram armazenados em um bucket do Amazon S3, eles recebem uma chave de objeto. Veja abaixo um exemplo de URL para um √∫nico objeto em um bucket chamado doc, com uma chave de objeto composta pelo prefixo 2006-03-01 e o arquivo nomeado AmazonS3.html.

<div align="center">

![URL AmazonS3](<Images Sprint6/Link Endere√ßo AmazonS3.png>)

</div>

### Atividade 1

**_Qual dos seguintes elementos faz parte de um URL de objeto do Amazon S3?_**

**_Resposta:_** Chave do objeto e Bucket.

## Veracidade

Quando se tem dados que n√£o s√£o controlados, provenientes de v√°rios sistemas diferentes e n√£o consegue fazer curadoria dos dados de maneiras significativas, voc√™ sabe que tem um problema de veracidade.

+ **Integridade dos Dados:** √© a manuten√ß√£o e a garantia de precis√£o e consist√™ncia dos dados durante todo o seu ciclo de vida.

+ **Veracidade:** dos dados √© o grau em que os dados s√£o exatos, precisos e confi√°veis.

<div align="center">

![Veracidade](<Images Sprint6/Veracidade.jpg>)

**Fonte: [AWS Skill Builder](https://explore.skillbuilder.aws/learn/course/internal/view/elearning/570/data-analytics-fundamentals-portuguese)**

</div>

Para garantir a integridade dos dados durante todas essas etapas, voc√™ pode seguir as seguintes pr√°ticas:

+ **Cria√ß√£o de Dados:**

    + Estabele√ßa padr√µes e pol√≠ticas para a entrada de dados corretos desde o in√≠cio.
    + Utilize valida√ß√µes e verifica√ß√µes para garantir que os dados criados estejam livres de erros.

+ **Agrega√ß√£o de Dados:**

    + Mantenha documenta√ß√£o detalhada sobre como os dados s√£o agregados e de onde eles v√™m.
    + Verifique a integridade dos dados ap√≥s a agrega√ß√£o para identificar qualquer discrep√¢ncia.

+ **Armazenamento de Dados:**

    + Armazene dados em sistemas seguros e resilientes.
    + Implemente controles de acesso para proteger os dados contra altera√ß√µes n√£o autorizadas.

+ **Acesso aos Dados:**

    + Controle o acesso aos dados, garantindo que apenas pessoas autorizadas possam visualiz√°-los ou modific√°-los.
    + Registre todas as a√ß√µes de acesso para fins de auditoria.

+ **Arquivamento de Dados:**

    + Arquive dados de acordo com pol√≠ticas de reten√ß√£o bem definidas.
    + Verifique a integridade dos dados ao longo do processo de arquivamento.

+ **Compartilhamento de Dados:**

    + Estabele√ßa pol√≠ticas claras de compartilhamento de dados, incluindo permiss√µes e restri√ß√µes.
    + Utilize m√©todos seguros para compartilhar dados externamente, quando necess√°rio.

Como discutimos, bancos de dados relacionais dependem de esquemas de banco de dados para organizar o conte√∫do dentro do banco de dados e impor a integridade referencial e de dom√≠nio. Os programadores tamb√©m usam esses esquemas ao escrever o software para interagir com o banco de dados. Alguns desses esquemas s√£o:

+ **Esquemas de Dados:** Um esquema de dados √© o conjunto de metadados usado pelo banco de dados para organizar objetos de dados e impor restri√ß√µes de integridade. O esquema define os atributos do banco de dados, fornecendo as descri√ß√µes de cada objeto e como ele interage com outros objetos no banco de dados. Um ou mais esquemas podem residir no mesmo banco de dados.

+ **Esquemas L√≥gicos:** Os esquemas l√≥gicos se concentram nas restri√ß√µes a serem aplicadas aos dados no banco de dados. Isso inclui a organiza√ß√£o de tabelas, visualiza√ß√µes e verifica√ß√µes de integridade.

+ **Esquemas F√≠sicos:** Os esquemas f√≠sicos se concentram no armazenamento real de dados em disco ou em um reposit√≥rio de nuvem. Esses esquemas t√™m detalhes sobre os arquivos, √≠ndices, tabelas particionadas, clusters e muito mais.

### Atividade 1

**_Em que est√°gio do ciclo de vida dos dados os consumidores testar√£o a veracidade dos dados?_**

**_Resposta:_** Compartilhamento.

### Atividade 2

**_Quais das perguntas a seguir devem ser feitas ao se preparar para uma avalia√ß√£o da integridade dos dados?_**

**_Resposta:_** Qual deve ser a limpeza?, O que √© uma altera√ß√£o aceit√°vel? e Os dados originais t√™m valor?

### Atividade 3

**_Fa√ßa a correspond√™ncia entre cada tipo de integridade ou esquema e a respectiva defini√ß√£o._**

**_Resposta:_**

| Integridade | Defini√ß√£o |
|---|---|
| Integridade relacional | Garante que ambos os membros de uma rela√ß√£o permane√ßam consistentes |
| Integridade da entidade | Garante que os valores em um campo permane√ßam consistentes |
| Esquema de informa√ß√µes | Um banco de dados de metadados contendo informa√ß√µes sobre todos os objetos do banco de dados |
| Esquema l√≥gico | Lista as restri√ß√µes, rela√ß√µes e propriedades de tabelas e exibi√ß√µes em um banco de dados |

&nbsp;

Para manter a veracidade nos dados armazenados, consist√™ncia √© essencial. Quando dados s√£o armazenados como arquivos, a consist√™ncia √© controlada pelo aplicativo que est√° desenvolvendo os arquivos. Quando os dados s√£o armazenados em um banco de dados, a consist√™ncia √© responsabilidade do banco de dados que os armazena. 

+ **ACID:** Acr√¥nimo para Atomicidade, Consist√™ncia, Isolamento e Durabilidade. √â um m√©todo para manter a consist√™ncia e a integridade em um banco de dados estruturado.

    O objetivo de um banco de dados compat√≠vel com ACID √© retornar a vers√£o mais recente de todos os dados e garantir que os dados inseridos no sistema atendam a todas as regras e restri√ß√µes atribu√≠das em todos os momentos.

+ **BASE:** Acr√¥nimo para BAsicamente dispon√≠vel, eStado flex√≠vel, Eventualmente consistente. √â um m√©todo para manter a consist√™ncia e a integridade em um banco de dados estruturado ou semiestruturado.

    O objetivo √© que a altera√ß√£o acabe sendo totalmente consistente em toda a frota. 

<div align="center">

![Tabela ACID x BASE](<Images Sprint6/Tabela ACID x BASE.png>)

**Fonte: [AWS Skill Builder](https://explore.skillbuilder.aws/learn/course/internal/view/elearning/570/data-analytics-fundamentals-portuguese)**

</div>

### Atividade 4

**_Quando a consist√™ncia das altera√ß√µes em todas as inst√¢ncias √© a minha principal preocupa√ß√£o, a conformidade com ___________ √© o m√©todo apropriado para impor a conformidade._**

**_Resposta:_** ACID.

### Atividade 5

**_Quando os dados est√£o sendo gerados em um ambiente altamente ativo e a disponibilidade √© minha principal preocupa√ß√£o, a conformidade com ___________ √© o m√©todo apropriado para impor a conformidade._**

**_Resposta:_** BASE.

**Extra√ß√£o, transforma√ß√£o e carregamento (ETL)** √© o processo de coletar dados de origens brutas e transform√°-los em um tipo comum. Esses novos dados s√£o carregados em um local final para serem disponibilizados para avalia√ß√£o e inspe√ß√£o anal√≠ticas. Em ambientes modernos baseados na nuvem, geralmente nos referimos a esse processo como ELT (extra√ß√£o, transforma√ß√£o e carregamento). As etapas s√£o simplesmente executadas em uma ordem diferente, mas o resultado √© o mesmo.

H√° quatro √°reas principais para as quais voc√™ deve planejar na etapa de **extra√ß√£o dos dados**.

1. Voc√™ deve identificar onde todos os dados de origem residem. Esses dados podem ser armazenados on-premises por sua empresa, mas tamb√©m podem incluir dados encontrados on-line.

2. Voc√™ deve planejar cuidadosamente quando a extra√ß√£o ocorrer√° devido ao poss√≠vel impacto do processo de c√≥pia no sistema de origem.

3. Voc√™ deve planejar onde os dados ser√£o armazenados durante o processamento. Ele geralmente √© chamado de local intermedi√°rio.

4. Voc√™ deve planejar com quefrequ√™ncia a extra√ß√£o deve ser repetida.

Na etapa de **transforma√ß√£o dos dados**, devemos seguir um formato uniforme e consult√°vel, essa fase envolve o uso de uma s√©rie de regras e algoritmos para inserir os dados no formato final. A limpeza de dados tamb√©m ocorre durante essa parte do processo.

As transforma√ß√µes podem ser b√°sicas, como a limpeza de dados para atualizar formatos ou fazer substitui√ß√µes de dados. Pode ser a substitui√ß√£o de valores NULL por zero ou a substitui√ß√£o da palavra feminino pela letra F. Essas altera√ß√µes aparentemente pequenas podem ter um grande impacto sobre a utilidade desses dados para analistas posteriormente, no processo de visualiza√ß√£o.

Por fim, temos a etapa de **carregar os dados**, onde escolhemos um local para carregar os dados rec√©m-transformados. Na fase de transforma√ß√£o ditamos o formato que o datastore ter√°, esse formato pode ser um banco de dados, um data warehouse ou um data lake. Assim que o processo for conclu√≠do com √™xito, os dados nesse local estar√£o prontos para serem analisados.

Quando se trata de executar o componente de transforma√ß√£o de dados do ETL, h√° duas op√ß√µes na AWS: o Amazon EMR e o AWS Glue. Esses dois servi√ßos fornecem resultados semelhantes, mas exigem diferentes quantidades de conhecimento e investimento de tempo.

+ **Amazon EMR:** √â uma abordagem mais pr√°tica para criar seu pipeline de dados.

+ **AWS Glue:** √â uma ferramenta de ETL gerenciada sem servidor que oferece uma experi√™ncia muito mais simplificada do que o Amazon EMR.

### Atividade 6

**_Quais das afirma√ß√µes a seguir sobre os servi√ßos de ETL da AWS s√£o verdadeiras?_**

**_Resposta:_** 
Os servi√ßos de ETL da AWS podem transformar dados relacionais em dados n√£o relacionais e Os servi√ßos de ETL da AWS podem transformar dados em arquivos de dados armazenados no Amazon S3.

## Valor

Quando h√° grandes volumes de dados usados para corroborar algumas informa√ß√µes valiosas, voc√™ pode estar perdendo o valor dos seus dados.

Armazenar terabytes de dados que nunca ningu√©m ver√°, analisar√° ou visualizar√° √© um esfor√ßo in√∫til. O esfor√ßo real deve ser para descobrir qual √© o valor real dos dados e aprender maneiras de extrair esse valor dos terabytes de dados coletados pela sua empresa.

<div align="center">

![Valor](<Images Sprint6/Valor.jpg>)

**Fonte: [AWS Skill Builder](https://explore.skillbuilder.aws/learn/course/internal/view/elearning/570/data-analytics-fundamentals-portuguese)**

</div>

An√°lise de informa√ß√µes √© o processo de an√°lise de informa√ß√µes para encontrar o valor contido nelas. Tendo isso em mente, podemos afirmar que podemos seguir as seguintes analises:

+ **Avalia√ß√£o Descritiva: O QUE ACONTECEU?** Utiliza-se dos dados dispon√≠veis como √∫nica entrada considerada, exiginto maior n√≠vel de esfor√ßo e interpreta√ß√£o dos humanos.

+ **Avalia√ß√£o Diagn√≥stica: POR QUE ISSO ACONTECEU?** Ocorre a compara√ß√£o dos dados hist√≥ricos com os outros dados, analisando se h√° depend√™ncias e padr√µes que podem dispor de respostas.

+ **Avalia√ß√£o Preditiva: O QUE ACONTECER√Å?** Utiliza das informa√ß√µes geradas da avalia√ß√£o descritiva e diagn√≥stica, prevendo eventos futuros.

+ **Avalia√ß√£o Prescritiva: O QUE DEVO FAZER?** Utilizada para receitar a√ß√µes a serem tomadas com base nos dados fornecidos at√© ent√£o.

+ **Avalia√ß√£o Cognitiva e Artificial: QUAIS S√ÉO AS A√á√ïES RECOMENDADAS?** Envolve o uso de tecnologia e algoritmos para entender e avaliar processos mentais, tomar decis√µes ou melhorar o desempenho cognitivo.

√â importante ter uma compreens√£o s√≥lida da velocidade que voc√™ pode esperar dos diferentes tipos de processamento.

+ **An√°lise em Batch:** Envolve consulta a grandes quantidades de dados ‚Äúfrios‚Äù. A an√°lise em batch √© implementada em grandes conjuntos de dados para produzir um grande n√∫mero de resultados anal√≠ticos de forma regular.

+ **An√°lise Interativa:** Envolve a execu√ß√£o de consultas intrincadas em conjuntos de dados complexos em altas velocidades. Esse tipo de an√°lise √© interativo, pois permite que o usu√°rio consulte e veja os resultados imediatamente.

+ **An√°lise em Stream:** Exige a ingest√£o de uma sequ√™ncia de dados e a atualiza√ß√£o incremental de m√©tricas, relat√≥rios e estat√≠sticas de resumo em resposta a cada registro de dados recebido. Esse m√©todo √© mais adequado para fun√ß√µes de monitoramento e resposta em tempo real.

Abaixo apresentamos os componentes e os servi√ßos envolvidos:

1. **Ingerir/Coletar:** Voc√™ pode coletar dados de duas maneiras: em batches grandes ou em um processo de stream.

<div align="center">

![Coletar Servi√ßos](<Images Sprint6/Coletar dados - Servi√ßos.png>)

</div>

2. **Armazenar:** Voc√™ pode armazenar dados de duas maneiras: armazenando objetos ou armazenando registros em um banco de dados ou data warehouse.

<div align="center">

![Armazenar Servi√ßos](<Images Sprint6/Armazenar dados - Servi√ßos.png>)

</div>

3. **Processar:** O processamento e a an√°lise de dados s√£o feitos em v√°rios est√°gios diferentes, sendo um processo iterativo. H√° o processamento e a limpeza iniciais pelos quais os dados passar√£o. Em seguida, os dados ser√£o colocados em um datastore anal√≠tico. Isso pode ocorrer no n√≠vel de objeto ou registro. Os dados podem ser reprocessados e analisados a partir do datastore anal√≠tico.

<div align="center">

![Processar Servi√ßos](<Images Sprint6/Processar dados - Servi√ßos.png>)

</div>

4. **Consumir/Visualizar:** Voc√™ pode consumir e visualizar dados de diversas maneiras, usando uma grande variedade de ferramentas. Muitas vezes, a ferramenta para consumir e visualizar os dados √© a mesma.

<div align="center">

![Consumir Servi√ßos](<Images Sprint6/Consumir dados - Servi√ßos.png>)

</div>

### Atividade 1

**_Fa√ßa a correspond√™ncia entre cada pergunta e o tipo de an√°lise necess√°rio para respond√™-la._**

**_Resposta:_**

<div align="center">

| Tipo de An√°lise | Pergunta |
| --- | --- |
| Descritivo | Quais foram as vendas totais em abril? |
| Diagn√≥stico | Qual √© o total de vendas ano a ano para a regi√£o √Åsia-Pac√≠fico? |
| Prescritivo | Quais produtos devo comprar se gosto do time Seattle Seahawks? |
| Preditivo | Qual √© o crescimento projetado para interna√ß√µes relacionadas a tabagismo no pr√≥ximo ano? |
| Cognitivo | Qual √© o n√∫mero m√©dio de ve√≠culos detectados pela minha campainha de v√≠deo? |

</div>

&nbsp;

> ‚ÄúA an√°lise de dados eficaz √© mais do que apenas dados e gr√°ficos. √â sobre encontrar e contar uma hist√≥ria.‚Äù - Glen Rabie

Os relat√≥rios anal√≠ticos s√£o apresentados em v√°rios formatos e tamanhos diferentes. A origem dos dados raramente afeta os relat√≥rios resultantes. Os relat√≥rios s√£o organizados para atender √†s necessidades dos consumidores dos relat√≥rios. Os relat√≥rios podem sem:

+ Relat√≥rios Est√°ticos;

+ Relat√≥rios Interativos;

+ Pain√©is.

Relat√≥rios e pain√©is s√£o compostos por v√°rios gr√°ficos e tabelas para responder perguntas.

### Atividade 2

**_Quais das op√ß√µes a seguir s√£o tipos de relat√≥rio? (Escolha tr√™s alternativas.)_**

**_Resposta:_** Est√°tico, Interativo e Painel.

&nbsp;

# 2. Data Analytics on AWS - Business

## Oportunidade de Mercado

+ Dados como um ativo estrat√©gico para as empresas;
+ Desafios da an√°lise de dados enfrentados pelas atuais empresas;
+ Pipeline de an√°lise de dados e o Data Flywheel.

Inicialmente devemos ter em mente o que √© Big Data, podemos afirmar que s√£o dados elevada quantidade e com exponencial crescimento, tornando seu armazenamento e gerenciamento um desafio. Seus principais aspectos s√£o: Volume, Velocidade, Variedade e Veracidade. 

Os dados obtidos se transformam em **insights**, assim obt√©m de valor econ√¥mico e oferece servi√ßos personalizados, dados s√£o informa√ß√µes sobre pessoas, eventos, itens e transa√ß√µes, estas informa√ß√µes precisam ser transmitidas, processadas, analisadas e armazenadas. 

> **Obs: Insight √© a compreens√£o de uma causa e efeito espec√≠ficos dentro de um contexto espec√≠fico.**

Assim como apresentado no m√≥dulo passado, o Big Data possui os 4 V's nas suas caracter√≠sticas, s√£o estes:

+ **Volume:** Escala de tamanho de dados;

+ **Velocidade:** Taxa de cria√ß√£o e crescimento dos dados;

+ **Variedade:** Variedade dos formatos;

+ **Veracidade:** Incerteza dos dados.

As empresas orientadas por dados veem e tratam os dados como ativo estrat√©gico, isto √©, seguem os seguintes passos:

1. Coletar e reter todos os dados;
2. Transformam dados em insights;
3. Disponibilizar dados para usu√°rios e clientes relevantes;
4. Criar novos produtos e servi√ßos;
5. Invista em tecnologias de processamento de dados.

H√° muitas formas de analisarmos os dados, algumas ferramentas s√£o:

+ Hadoop (2006);
+ ElasticSearch (2010);
+ Presto (2012);
+ Spark (2014).

Um pipeline de dados √© uma s√©rie de etapas de processamento para preparar dados corporativos para an√°lise. 

<div align="center">

![Pipeline Dados](<Images Sprint6/Pipeline Dados.png>)

**Fonte: [Data Science Tech](https://blog.dsbrigade.com/pipeline-de-dados-com-servicos-aws/)**

</div>

Para criarmos um bom pipeline de an√°lise de dados com AWS podemos utilizar das seguintes ferramentas para cada uma das etapas:

<div align="center">

| Etapa | Ferramenta AWS |
|---|---|
| Coletar | Amazon Kinesis Data Streams, Amazon Kinesis Data Firehouse, AWS Snowball, AWS Direct Connect |
| Armazenamento | Amazon S3, Amazon S3 Glacier, Amazon DynamoDB, Amazon RDS, Amazon ES, Amazon CloudSearch, Amazon Aurora |
| Processar / Analisar | Amazon EMR, Amazon Athena, Amazon Redshift, Amazon Kinesis Data Analytics, Amazon SageMaker |
| Visualizar | Amazon QuickSight |

</div>

&nbsp;

### Atividade 1

**_Qual √© a primeira etapa de uma jornada do cliente para se tornar uma empresa orientada por dados?_**

**_Resposta:_** Migrar dados on-premises para a nuvem.

### Atividade 2

**_Quais s√£o as quatro caracter√≠sticas do big data?_**

**_Resposta:_** Volume, velocidade, variedade, veracidade.

### Atividade 3

**_Quais s√£o os dois desafios comuns que as empresas enfrentam na an√°lise de big data?_**

**_Resposta:_** Falta de conhecimento t√©cnico e privacidade e seguran√ßa de dados.

### Atividade 4

**_Quais s√£o os componentes do pipeline de dados?_**

**_Resposta:_** Coletar, armazenar, processar e analisar, visualizar.

## Solu√ß√µes de An√°lise de Dados na AWS

A Amazon Web Services (AWS) oferece uma ampla gama de servi√ßos e solu√ß√µes para an√°lise de dados, permitindo que as organiza√ß√µes processem, armazenem, analisem e visualizem grandes volumes de dados de maneira eficiente e escal√°vel. Abaixo, vou destacar algumas das principais solu√ß√µes de an√°lise de dados na AWS:

<div align="center">

![Extra√ß√£o Data Lakes](<Images Sprint6/Extra√ß√£o Data Lakes.png>)

**Fonte: [Amazon AWS](https://aws.amazon.com/pt/blogs/aws-brasil/como-extrair-valor-dos-seus-dados-com-data-lakes-e-analises-na-aws/)**

</div>

+ **Amazon Redshift:** Um data warehouse totalmente gerenciado que permite armazenar e analisar grandes volumes de dados usando SQL. √â altamente escal√°vel e integrado com outras ferramentas de an√°lise, como o Amazon QuickSight.

+ **Amazon Athena:** Um servi√ßo de an√°lise interativa que permite consultar dados diretamente no Amazon S3 usando SQL padr√£o, sem a necessidade de carregar dados para um banco de dados.

+ **Amazon EMR (Elastic MapReduce):** Uma estrutura de computa√ß√£o em nuvem que permite processar e analisar grandes volumes de dados usando estruturas de processamento distribu√≠do, como Hadoop e Spark.

+ **Amazon Quicksight:** Uma ferramenta de visualiza√ß√£o de dados totalmente gerenciada que permite criar pain√©is interativos e relat√≥rios com facilidade. √â integrada com muitos outros servi√ßos da AWS.

+ **AWS Glue:** Um servi√ßo de ETL (Extra√ß√£o, Transforma√ß√£o e Carga) totalmente gerenciado que simplifica o processo de prepara√ß√£o de dados para an√°lise, automatizando tarefas de integra√ß√£o e transforma√ß√£o de dados.

+ **Amazon Kinesis:** Uma plataforma para coletar, processar e analisar dados em tempo real, como streaming de v√≠deo, logs e dados de sensores.

+ **AWS Data Pipeline:** Um servi√ßo que permite orquestrar e automatizar fluxos de trabalho de dados, facilitando a movimenta√ß√£o de dados entre diferentes servi√ßos da AWS e fontes externas.

+ **AWS Data Lake:** Um conceito que envolve a cria√ß√£o de um reposit√≥rio centralizado de dados em bruto, geralmente usando o Amazon S3, para armazenar todos os tipos de dados antes da an√°lise. Isso permite flexibilidade na an√°lise posterior.

+ **AWS Glue DataBrew:** Uma ferramenta de prepara√ß√£o de dados visual que ajuda a limpar, normalizar e transformar dados de maneira f√°cil e eficiente.

+ **Amazon SageMaker:** Uma plataforma de aprendizado de m√°quina totalmente gerenciada que permite criar, treinar e implantar modelos de aprendizado de m√°quina com facilidade para an√°lise preditiva.

+ **Amazon Timestream:** Um banco de dados de s√©ries temporais totalmente gerenciado que √© otimizado para armazenar e consultar dados de s√©ries temporais, como m√©tricas de IoT e registros de aplicativos.

+ **Amazon Managed Grafana:** Um servi√ßo que permite criar e implantar pain√©is de observabilidade com o Grafana sem a necessidade de gerenciar a infraestrutura subjacente.

Essas s√£o apenas algumas das muitas solu√ß√µes de an√°lise de dados dispon√≠veis na AWS. A escolha da solu√ß√£o depender√° das necessidades espec√≠ficas da sua organiza√ß√£o, do tipo de dados que voc√™ est√° lidando e dos seus objetivos de an√°lise. A AWS oferece flexibilidade para construir pipelines de dados e arquiteturas de an√°lise personalizadas com base nas suas necessidades.

### Atividade 1

**_Qual √© o nome da abordagem de arquitetura que permite √†s empresas armazenar todos os dados (estruturados, n√£o estruturados e semiestruturados) em um √∫nico reposit√≥rio?_**

**_Resposta:_** Data Lake.

### Atividade 2

**_Qual √© o nome do servi√ßo de data warehouse da AWS?_**

**_Resposta:_** Amazon RedShift.

### Atividade 3

**_Qual √© o nome do servi√ßo de visualiza√ß√£o de dados da AWS?_**

**_Resposta:_** Amazon QuickSight.

### Atividade 4

**_Qual servi√ßo da Nuvem AWS voc√™ deve usar para modernizar data warehouses herdados?_**

**_Resposta:_** Amazon Redshift.

### Atividade 5

**_Qual produto da AWS voc√™ usaria para dados em transmiss√£o?_**

**_Resposta:_** Amazon Kinesis.

### Atividade 6

**_Quais dessas solu√ß√µes podem ser aplicadas usando algoritmos para encontrar padr√µes nos dados depois que eles s√£o protegidos em um data lake?_**

**_Resposta:_** Governan√ßa de dados.

## 3. Conversas de neg√≥cios

As conversas de neg√≥cios relacionadas √† Amazon Web Services (AWS) geralmente envolvem discuss√µes sobre como a AWS pode atender √†s necessidades de uma organiza√ß√£o em termos de computa√ß√£o em nuvem e servi√ßos relacionados. Aqui est√£o alguns tipos comuns de conversas de neg√≥cios relacionadas √† AWS:

+ **Planejamento de Migra√ß√£o para a Nuvem:** Muitas organiza√ß√µes consideram mover suas cargas de trabalho locais para a nuvem da AWS. As conversas de neg√≥cios aqui se concentram em estrat√©gias de migra√ß√£o, custos associados, seguran√ßa, conformidade e benef√≠cios da mudan√ßa para a nuvem.

+ **Arquitetura de Nuvem:** Empresas discutem como projetar suas aplica√ß√µes e infraestrutura na AWS para garantir escalabilidade, desempenho e alta disponibilidade. Isso inclui escolher servi√ßos adequados, como servidores EC2, bancos de dados gerenciados, balanceadores de carga, etc.

+ **An√°lise de Custos:** Conversas relacionadas a otimiza√ß√£o de custos, identificando maneiras de reduzir despesas ao utilizar estrategicamente os recursos da AWS, como inst√¢ncias reservadas, or√ßamentos e relat√≥rios de uso.

+ **Seguran√ßa e Conformidade:** Discuss√µes sobre as pr√°ticas de seguran√ßa da AWS e como atender aos requisitos de conformidade da ind√∫stria, como GDPR, HIPAA, etc.

+ **P√∫blico-Alvo:** Esta se√ß√£o pode explicar quem √© o p√∫blico-alvo do m√≥dulo de treinamento. Pode ser direcionado a profissionais de vendas, gerentes de contas, consultores de solu√ß√µes, arquitetos de solu√ß√µes ou qualquer pessoa envolvida em vendas, consultoria ou parcerias relacionadas √† AWS.

+ **Perguntas de Descoberta:** Essa se√ß√£o abordaria as perguntas que os profissionais envolvidos nas conversas de neg√≥cios relacionadas √† AWS devem fazer para entender as necessidades e desafios do cliente. Perguntas de descoberta s√£o fundamentais para personalizar as solu√ß√µes da AWS de acordo com os requisitos espec√≠ficos do cliente. Exemplos de perguntas de descoberta podem incluir:

    + Quais s√£o os desafios de neg√≥cios que sua organiza√ß√£o est√° enfrentando?
    + Qual √© a infraestrutura de TI atual da sua empresa?
    + Quais s√£o seus objetivos de neg√≥cios de curto e longo prazo?
    + Voc√™ tem requisitos de conformidade espec√≠ficos?
    + Como voc√™ lida com a escalabilidade e disponibilidade de recursos de TI?

Alguns exemplos de obje√ß√µes comuns podem incluir preocupa√ß√µes com seguran√ßa, custos, complexidade ou resist√™ncia √† migra√ß√£o para a nuvem. O treinamento pode incluir estrat√©gias para superar essas obje√ß√µes, como a apresenta√ß√£o de estudos de caso, demonstra√ß√µes de seguran√ßa robusta na AWS e an√°lises de custo-benef√≠cio.

# Exerc√≠cios - Laborat√≥rios AWS

## 2. Lab AWS S3

**Etapa 1: Criar um bucket.**

As instru√ß√µes a seguir fornecem uma vis√£o geral de como criar seus buckets para hospedagem de conte√∫do est√°tico.

<div align="center">

![Criar bucket](<Images Sprint6/Criar bucket.png>)

![Criar bucket2](<Images Sprint6/Criar bucket2.png>)

</div>

**Etapa 2: Habilitar hospedagem de site est√°tico.**

Depois de criar um bucket, voc√™ pode habilitar a hospedagem de site est√°tico nele.

<div align="center">

![Hospedagem](<Images Sprint6/Hospedagem.png>)

![Hospedagem2](<Images Sprint6/Hospedagem2.png>)
</div>

**Etapa 3: editar as configura√ß√µes do Bloqueio de acesso p√∫blico.**

Por padr√£o, o Amazon S3 bloqueia o acesso p√∫blico √† sua conta e aos seus buckets. Se quiser usar um bucket para hospedar um site est√°tico, use estas etapas para editar as configura√ß√µes de bloqueio de acesso p√∫blico.

<div align="center">

![Acesso p√∫blico](<Images Sprint6/Acesso p√∫blico.png>)

</div>

**Etapa 4: Adicionar pol√≠tica de bucket que torna o conte√∫do do bucket publicamente dispon√≠vel.**

Depois de editar as configura√ß√µes do bloqueio de acesso p√∫blico do S3, √© poss√≠vel adicionar uma pol√≠tica de bucket para conceder acesso p√∫blico de somente leitura ao bucket. Ao conceder um acesso p√∫blico de leitura, qualquer pessoa na Internet poder√° acessar seu bucket.

<div align="center">

![Pol√≠tica bucket](<Images Sprint6/Pol√≠tica bucket.png>)

</div>

**Etapa 5: Configurar um documento de √≠ndice.**

Quando voc√™ habilita a hospedagem de sites est√°ticos para seu bucket, deve informar o nome do documento de √≠ndice (por exemplo, index.html). Naturalmente, o arquivo informado dever√° estar presente no bucket para que a configura√ß√£o tenha efeito.

<div align="center">

![Documento index](<Images Sprint6/Documento index.png>)

</div>

**Etapa 6: configurar documento de erros.**

Depois de habilitar a hospedagem de sites est√°ticos para seu bucket, fa√ßa upload para o bucket de um arquivo HTML para notifica√ß√£o de erros.

<div align="center">

![Todos documentos](<Images Sprint6/Todos documentos.png>)

</div>

**Etapa 7: testar o endpoint do site.**

Depois de configurar a hospedagem de site est√°tico para seu bucket, voc√™ pode test√°-lo em seu navegador.

<div align="center">

![Endpoint](<Images Sprint6/Endpoint.png>)

&nbsp;

</div>

## 3. Lab AWS Athena

**Etapa 1: Configurar Athena.**

<div align="center">

![Pasta queries](<Images Sprint6/Pasta queries.png>)

![Localizando query](<Images Sprint6/Localiza√ß√£o Query.png>)

</div>

**Etapa 2: Criar um banco de dados.**

<div align="center">

![Create meubanco](<Images Sprint6/Create meubanco.png>)

</div>

**Etapa 3: Criar uma tabela.**

Agora que voc√™ tem um banco de dados, pode criar uma tabela do Athena para ele.

<div align="center">

![Criar tabela](<Images Sprint6/Criar tabela.png>)

![Criar tabela 2](<Images Sprint6/Criar tabela2.png>)

![Teste query](<Images Sprint6/Teste query.png>)

</div>

```sql
select nome 
from nomedobanco.nomedatabela 
where ano = 1999 
order by total 
limit 15;

# Output

#	nome
1	Adaiah
2	Aanya
3	Abinaya
4	Abriona
5	Achsah
6	Aalijah
7	Aania
8	Aaren
9	Abbigaile
10	Abla
11	Abrianne
12	Aby
13	Accalia
14	Adalee
15	Abish
```

**Desafio: Crie uma consulta que lista os 3 nomes mais usados em cada d√©cada desde o 1950 at√© hoje.**

<div align="center">

![Desafio](<Images Sprint6/Desafio.png>)

![Desafio2](<Images Sprint6/Desafio2.png>)
</div>

```sql
WITH DadosPorDecada AS (
  SELECT
    nome,
    ano,
    CASE
      WHEN ano BETWEEN 1950 AND 1959 THEN '1950s'
      WHEN ano BETWEEN 1960 AND 1969 THEN '1960s'
      WHEN ano BETWEEN 1970 AND 1979 THEN '1970s'
      WHEN ano BETWEEN 1980 AND 1989 THEN '1980s'
      WHEN ano BETWEEN 1990 AND 1999 THEN '1990s'
      WHEN ano BETWEEN 2000 AND 2009 THEN '2000s'
      WHEN ano BETWEEN 2010 AND 2019 THEN '2010s'
      WHEN ano BETWEEN 2020 AND 2029 THEN '2020s'
      ELSE 'Outras'
    END AS decada,
    total
  FROM meubanco.nomes
)
, DecadasTop3 AS (
  SELECT
    decada,
    nome,
    SUM(total) AS total_por_nome,
    ROW_NUMBER() OVER (PARTITION BY decada ORDER BY SUM(total) DESC) AS rank
  FROM DadosPorDecada
  GROUP BY decada, nome
)
SELECT
  decada,
  nome,
  total_por_nome
FROM DecadasTop3
WHERE rank <= 3
ORDER BY decada, total_por_nome DESC;
```

&nbsp;

## 4. Lab AWS Lambda

**Etapa 1: Criar a fun√ß√£o do Lambda.**

<div align="center">

![Criar fun√ß√£o](<Images Sprint6/Criar fun√ß√£o.png>)

</div>

**Etapa 2: Construir o c√≥digo.**

<div align="center">

![Origem do c√≥digo](<Images Sprint6/Origem do c√≥digo.png>)

![Origem do c√≥digo 2](<Images Sprint6/Origem do c√≥digo2.png>)

</div>

**Etapa3: Criar uma Layer.**

<div align="center">

![Dockerfile](<Images Sprint6/Dockerfile.png>)

![Layer 1](<Images Sprint6/Layer1.png>)

![Layer 2](<Images Sprint6/Layer2.png>)

![Layer 3](<Images Sprint6/Layer3.png>)

![Criar camada](<Images Sprint6/Criar camada.png>)

</div>

**Etapa 4: Utilizando a Layer.**

<div align="center">

![Configura√ß√µes camada](<Images Sprint6/Configura√ß√µes camada.png>)

![Response c√≥digo](<Images Sprint6/Response c√≥digo.png>)

</div>

&nbsp;

# üìù Certifica√ß√£o

+ Certifica√ß√£o da conclu√ß√£o do curso Data Analytics Fundamentals de 4hrs.

<div align="center">

![Data Analytics Fundamentals](<Certification PNG/Data Analytics Fundamentals.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Data Analytics on AWS Business de 4hrs.

<div align="center">

![Data Analytics on AWS Business](<Certification PNG/Data Analytics on AWS Business.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Introduction to Amazon Kinesis Streams de 15m.

<div align="center">

![Amazon Kinesis Streams](<Certification PNG/Amazon Kinesis Streams.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Introduction to Amazon Kinesis Analytics de 7m.

<div align="center">

![Amazon Kinesis Analytics](<Certification PNG/Amazon Kinesis Analytics.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Introduction to Amazon Elastic MapReduce de 15m.

<div align="center">

![Amazon Elastic MapReduce](<Certification PNG/Amazon Elastic MapReduce.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Introduction to Amazon Athena de 10m.

<div align="center">

![Amazon Athena](<Certification PNG/Amazon Athena.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Introduction to Amazon Quicksight de 18m.

<div align="center">

![Amazon Quicksight](<Certification PNG/Amazon Quicksight.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Introduction to AWS IoT Analytics de 30m.

<div align="center">

![AWS IoT Analytics](<Certification PNG/AWS IoT Analytics.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Getting Started with Amazon Redshift de 1hr.

<div align="center">

![Getting Started with Amazon Redshift](<Certification PNG/Getting Started with Amazon Redshift.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Deep Dive into Concepts and Tools for Analyzing Streaming Data de 35m.

<div align="center">

![Deep Dive into Concepts and Tools for Analyzing Streaming Data](<Certification PNG/Deep Dive into Concepts and Tools for Analyzing Streaming Data.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Best Practices for Data Warehousing with Amazon Redshift de 1hr30m.

<div align="center">

![Best Practices for Data Warehousing with Amazon Redshift](<Certification PNG/Best Practices for Data Warehousing with Amazon Redshift.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Serverless Analytics de 25m.

<div align="center">

![Serverless Analytics](<Certification PNG/Serverless Analytics.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Why Analytics for Games de 25m.

<div align="center">

![Why Analytics for Games](<Certification PNG/Why Analytics for Games.png>)

</div>

+ Certifica√ß√£o da conclu√ß√£o do curso Data & Analytics - PB - AWS 6/10.

<div align="center">

![Data & Analytics - PB - AWS 6/10](<Certification PNG/Data & Analytics - PB - AWS 6-10.jpg>)

</div>

---